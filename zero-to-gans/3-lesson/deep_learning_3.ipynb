{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='../data/', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_loader:\n",
    "    print('images.shape', images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_loader:\n",
    "    print('images.shape', images.shape)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images,nrow=16).permute((1,2,0)))\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(xb):\n",
    "#     return xb @ w.t() + b\n",
    "\n",
    "# nn.Linear(in_size, out_size, ) 3 #tmp, humidyt sth /// 2 apples, oranges\n",
    "# nn.Linear(in_size, out_size) # 28 x 28 in one vector, 10 values -> probability which number\n",
    "\n",
    "## what if:\n",
    "# nn.linear(28*28), 16)\n",
    "# nn.linear(16, 10) -> czyli przepuszczamy to dwa razy, liczba 16 wyjeta lsoowa\n",
    "\n",
    "# def forward():\n",
    "#     out = self.linear1(xb)\n",
    "#     out = self.liners2(out)\n",
    "#     return out\n",
    "\n",
    "#in outher words: \n",
    "#out = self.linear2(self.linear1(xb))\n",
    "#out = (xb @ w1 + b) @ w2 + b2 = xb @ (w1 @ w2) + xb @ (b1 @ w1) + b2 = xb @ ((w1 @ w2) + (b1 @ w1)) + b2 = xb @ w3 + b2 = self.linear3() -> nic nie osiagnelismy czyli dwie warstwy to tyle samo co jedna\n",
    "\n",
    "# def forward():\n",
    "#     out = self.linear1(xb)\n",
    "#     out = F.relu(out) <- activation function, non-linearity aka Rectified Linear Unit\n",
    "#     out = self.liners2(out)\n",
    "#     return out i wtedy to dziaÅ‚a!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedforward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out) #sigmoid\n",
    "        #Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        # Generate predictions\n",
    "        out = self(images)\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        # Generate predictions\n",
    "        out = self(images)\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        # Calculate accuracy\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        # Combine losses\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "     \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(input_size, hidden_size=32, out_size=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Loss:', loss.item())\n",
    "    break\n",
    "\n",
    "print('outputs.shape:', outputs.shape)\n",
    "print('Sample outputs: \\n', outputs[:2].data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chose device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break;\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, service):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in val_loader:\n",
    "    print('xb.device:', xb.device)\n",
    "    print('yb:', yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mode, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=784, bias=True)\n",
       "  (linear2): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 2.3031866550445557, 'val_acc': 0.09042968600988388}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.1719, val_acc: 0.9508\n",
      "Epoch [1], val_loss: 0.1596, val_acc: 0.9496\n",
      "Epoch [2], val_loss: 0.1052, val_acc: 0.9668\n",
      "Epoch [3], val_loss: 0.0896, val_acc: 0.9743\n",
      "Epoch [4], val_loss: 0.0866, val_acc: 0.9725\n"
     ]
    }
   ],
   "source": [
    "# 1:36.7\n",
    "\n",
    "#CPU 1:41.9\n",
    "# Epoch [0], val_loss: 0.2419, val_acc: 0.9300\n",
    "# Epoch [1], val_loss: 0.1730, val_acc: 0.9514\n",
    "# Epoch [2], val_loss: 0.1505, val_acc: 0.9570\n",
    "# Epoch [3], val_loss: 0.1448, val_acc: 0.9571\n",
    "# Epoch [4], val_loss: 0.1348, val_acc: 0.9588\n",
    "\n",
    "#GPU 1:37.8\n",
    "# Epoch [0], val_loss: 0.2215, val_acc: 0.9339\n",
    "# Epoch [1], val_loss: 0.1651, val_acc: 0.9518\n",
    "# Epoch [2], val_loss: 0.1970, val_acc: 0.9374\n",
    "# Epoch [3], val_loss: 0.1353, val_acc: 0.9608\n",
    "# Epoch [4], val_loss: 0.1208, val_acc: 0.9640\n",
    "\n",
    "history += fit(5, 0.5, model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.2219, val_acc: 0.9369\n",
      "Epoch [1], val_loss: 0.2177, val_acc: 0.9383\n",
      "Epoch [2], val_loss: 0.2139, val_acc: 0.9399\n",
      "Epoch [3], val_loss: 0.2113, val_acc: 0.9388\n",
      "Epoch [4], val_loss: 0.2067, val_acc: 0.9420\n"
     ]
    }
   ],
   "source": [
    "history += fit(5, 0.1, model, train_loader, val_loader)\n",
    "#0.9813 for RElu\n",
    "#0.9420 for sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [x['val_loss'] for x in history]\n",
    "plt.plot(losses, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [x['val_acc'] for x in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs No. of epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
